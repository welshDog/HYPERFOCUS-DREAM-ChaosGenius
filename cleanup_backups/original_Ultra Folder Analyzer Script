import os
import json
import hashlib
from pathlib import Path
from datetime import datetime
import mimetypes

# 📁 Main folder to analyze - Updated to analyze the current project folder
MAIN_FOLDER = Path("C:/Users/Lyndz/OneDrive/Desktop/HYPERFOCUS DREAM build idea")

# 📋 Collect file stats and organization issues
def analyze_folder_structure(base_path):
    report = {
        "summary": {
            "total_files": 0,
            "total_folders": 0,
            "file_types": {},
            "large_files": [],
            "duplicate_names": [],
            "organization_suggestions": [],
            "issues": []
        },
        "folder_analysis": {},
        "files": []
    }

    # Check if the base path exists
    if not base_path.exists():
        report["summary"]["issues"].append(f"Base folder does not exist: {base_path}")
        return report

    file_names = {}  # Track duplicate file names
    folder_file_counts = {}  # Track files per folder

    for root, dirs, files in os.walk(base_path):
        current_folder = Path(root)
        folder_name = current_folder.name if current_folder != base_path else "ROOT"
        
        # Folder analysis
        folder_file_counts[folder_name] = len(files)
        if folder_name not in report["folder_analysis"]:
            report["folder_analysis"][folder_name] = {
                "path": str(current_folder),
                "file_count": len(files),
                "subfolder_count": len(dirs),
                "file_types": {}
            }

        report["summary"]["total_folders"] += len(dirs)
        
        for file in files:
            report["summary"]["total_files"] += 1
            file_path = Path(root) / file
            file_ext = file_path.suffix.lower()
            mime_type, _ = mimetypes.guess_type(file_path)
            
            try:
                file_stat = file_path.stat()
                file_size_kb = round(file_stat.st_size / 1024, 2)
                file_size_mb = round(file_stat.st_size / (1024*1024), 2)
            except (OSError, PermissionError) as e:
                report["summary"]["issues"].append(f"Cannot access file: {file_path} - {e}")
                continue

            # File type distribution (global)
            if file_ext not in report["summary"]["file_types"]:
                report["summary"]["file_types"][file_ext] = 0
            report["summary"]["file_types"][file_ext] += 1

            # File type distribution (per folder)
            if file_ext not in report["folder_analysis"][folder_name]["file_types"]:
                report["folder_analysis"][folder_name]["file_types"][file_ext] = 0
            report["folder_analysis"][folder_name]["file_types"][file_ext] += 1

            # Track duplicate file names
            if file in file_names:
                file_names[file].append(str(file_path))
            else:
                file_names[file] = [str(file_path)]

            # Record file info
            file_info = {
                "path": str(file_path),
                "folder": folder_name,
                "name": file,
                "extension": file_ext,
                "mime_type": mime_type,
                "size_kb": file_size_kb,
                "size_mb": file_size_mb,
                "last_modified": datetime.fromtimestamp(file_stat.st_mtime).isoformat()
            }

            # Detect large files (>10MB)
            if file_size_mb > 10:
                report["summary"]["large_files"].append({
                    "path": str(file_path),
                    "size_mb": file_size_mb
                })

            # Detect potential issues
            if file_ext in [".log", ".bak", ".tmp", ".temp"]:
                report["summary"]["issues"].append(f"Temporary/backup file: {file_path}")
            if len(file) > 64:
                report["summary"]["issues"].append(f"Long file name (>64 chars): {file_path}")
            if " " in file and file_ext not in [".md", ".txt", ".html"]:
                report["summary"]["issues"].append(f"File name contains spaces: {file_path}")
            if file.startswith("~") or file.startswith("._"):
                report["summary"]["issues"].append(f"System/hidden file: {file_path}")

            report["files"].append(file_info)

    # Find duplicate file names
    for filename, paths in file_names.items():
        if len(paths) > 1:
            report["summary"]["duplicate_names"].append({
                "filename": filename,
                "locations": paths
            })

    # Generate organization suggestions
    if len(report["summary"]["file_types"]) > 20:
        report["summary"]["organization_suggestions"].append("Consider organizing files by type (images, documents, code, etc.)")
    
    if any(count > 50 for count in folder_file_counts.values()):
        report["summary"]["organization_suggestions"].append("Some folders have >50 files - consider creating subfolders")
    
    if report["summary"]["large_files"]:
        report["summary"]["organization_suggestions"].append("Consider moving large files to a dedicated storage folder")

    return report

# 🧠 Run analysis
print("🔍 Starting HYPERFOCUS DREAM project analysis...")
print(f"📁 Analyzing: {MAIN_FOLDER}")
diagnostic_report = analyze_folder_structure(MAIN_FOLDER)

# 💾 Save to file with proper error handling
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
filename = f"hyperfocus_project_analysis_{timestamp}.json"

# Save in the project root
output_path = MAIN_FOLDER / filename

try:
    with open(output_path, "w", encoding='utf-8') as f:
        json.dump(diagnostic_report, f, indent=2, ensure_ascii=False)
    print(f"✅ Analysis complete! Report saved to: {output_path}")
except Exception as e:
    print(f"❌ Failed to save report: {e}")
    exit(1)

# 📊 Display comprehensive summary
print(f"\n🎯 HYPERFOCUS DREAM PROJECT ANALYSIS SUMMARY")
print(f"=" * 60)
print(f"📁 Total folders: {diagnostic_report['summary']['total_folders']}")
print(f"📄 Total files: {diagnostic_report['summary']['total_files']}")
print(f"⚠️  Issues found: {len(diagnostic_report['summary']['issues'])}")

print(f"\n📊 TOP FILE TYPES:")
sorted_types = sorted(diagnostic_report['summary']['file_types'].items(), key=lambda x: x[1], reverse=True)
for ext, count in sorted_types[:10]:
    ext_display = ext if ext else "(no extension)"
    print(f"   {ext_display}: {count} files")

if diagnostic_report['summary']['large_files']:
    print(f"\n💾 LARGE FILES (>10MB):")
    for large_file in diagnostic_report['summary']['large_files'][:5]:
        print(f"   📦 {Path(large_file['path']).name}: {large_file['size_mb']:.1f}MB")

if diagnostic_report['summary']['duplicate_names']:
    print(f"\n🔄 DUPLICATE FILENAMES:")
    for dup in diagnostic_report['summary']['duplicate_names'][:5]:
        print(f"   📝 '{dup['filename']}' appears in {len(dup['locations'])} locations")

print(f"\n📂 FOLDER BREAKDOWN:")
sorted_folders = sorted(diagnostic_report['folder_analysis'].items(), key=lambda x: x[1]['file_count'], reverse=True)
for folder_name, data in sorted_folders[:10]:
    print(f"   📁 {folder_name}: {data['file_count']} files")

if diagnostic_report['summary']['organization_suggestions']:
    print(f"\n💡 ORGANIZATION SUGGESTIONS:")
    for suggestion in diagnostic_report['summary']['organization_suggestions']:
        print(f"   💭 {suggestion}")

if diagnostic_report['summary']['issues']:
    print(f"\n⚠️  TOP ISSUES:")
    for issue in diagnostic_report['summary']['issues'][:5]:
        print(f"   ⚠️  {issue}")

print(f"\n🎉 Analysis complete! Full report saved as JSON for detailed review.")